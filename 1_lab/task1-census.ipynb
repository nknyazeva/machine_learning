{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "Результат работы − отчет в формате ноутбуков IPython (ipynb-файл). Код пишется на Python3. Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: мне − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.    \n",
    "Выполнение лабораторных работ занимает значительное время, поэтому не рекомендуем оставлять их на последний вечер перед сдачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) получают за всю лабораторную работу 0 баллов. Если вы нашли решение какого-то из заданий в открытом источнике, необходимо в комментариях к коду указать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "**Важно!!!** Прочитайте [руководство по написанию кода](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html). Работы, где будут грубо нарушены принципы оформления кода, будут штрафоваться!    \n",
    "Также помните, что самая главная ошибка, которую надо избегать, - дублирование кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Правила сдачи\n",
    "Выполненную работу следует отправить на почту `nikmort@ya.ru` с указанием темы `[FBB hw <номер домашнего задани> Surname Name]`, например `FBB hw 2 Ivanov Petr`. Название отправляемого файла должно иметь следующий формат: `N_Surname_Name.ipynb`, где `N` — номер домашнего задания. Например, `2_Ivanov_Petr.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "В этой работе вам необходимо будет обучать модели машинного обучения, подбирать гиперпараметры, сравнивать и смешивать модели. Вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k. Каждый объект выборки — человек, для которого известны следующие признаки:\n",
    " - age\n",
    " - workclass\n",
    " - fnlwgt\n",
    " - education\n",
    " - education-num\n",
    " - marital-status\n",
    " - occupation\n",
    " - relationship\n",
    " - race\n",
    " - sex\n",
    " - capital-gain\n",
    " - capital-loss\n",
    " - hours-per-week\n",
    " \n",
    "Более подробно про признаки можно почитать [здесь](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). Целевой признак записан в переменной *>50K,<=50K*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрика качества\n",
    "\n",
    "Многие модели машинного обучения позволяют не только отнести объект к какому-нибудь из классов, но и выдать вероятность принадлежности $\\tilde{y}(x)$ к этому классу. Например, в задаче бинарной классификации по умолчанию мы классифицируем объект первым классом, если вероятность принадлежности 1-ому классу будет больше 50%. Однако, можно перенастроить модель и относить объект к первому классу, если это вероятность будет больше некоторого параметра $\\theta$.\n",
    "\n",
    "$$y(x) = \n",
    "\\begin{cases}\n",
    "+1, &\\text{если} \\; \\tilde{y}(x) \\geq \\theta \\\\\n",
    "-1, &\\text{если} \\; \\tilde{y}(x) < \\theta\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "В таких случаях удобно работать с метрикой ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретическая задача **(5 баллов)**. Определим понятие доли дефектных пар ответов классификатора. Пусть дан классификатор $a(x)$, который возвращает оценки принадлежности объектов классам: чем больше ответ классификатора, тем более он уверен в том, что данный объект относится к классу $+1$. Отсортируем все объекты по неубыванию ответа классификатора $a$: $x_{(1)}, \\dots, x_{(\\ell)}$. Обозначим истинные ответы на этих объектах через $y_{(1)}, \\dots, y_{(\\ell)}$.\n",
    "Тогда доля дефектных пар записывается как\n",
    "$$  \\text{DP}(a, X^\\ell)\n",
    "    =\n",
    "    \\frac{2}{\\ell (\\ell - 1)}\n",
    "    \\sum_{i < j}^{\\ell}\n",
    "        \\left[\n",
    "            y_{(i)} > y_{(j)}\n",
    "        \\right].\n",
    "$$\n",
    "\n",
    "Как данный функционал связан с площадью под ROC-кривой?\n",
    "Ответ должен быть дан в виде формулы, связывающей DP и AUC. Ответ должен быть обоснован."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры и гиперпараметры модели\n",
    "\n",
    "В задачах машинного обучения следует различать параметры модели и гиперпараметры. Параметры настраиваются в ходе обучения алгоритмом обучения (например, структура решающего дерева - рассматриваемые признаки в узлах и пороги), а гиперпараметры задаются заранее (например, максимальная глубина решающего дерева или число соседей в методе ближайших соседей). Как правило, у каждой из модели несколько гиперпараметров и нет универсального набора гиперпараметров: для каждой задачи нужно подбирать свой.\n",
    "\n",
    "Для поиска наилучших гиперпараметров часто используют перебор по сетке (grid search): для каждого гиперпараметра выбирается несколько значений, перебираются все комбинации значений и выбирается комбинация, на которой модель показывает лучшее качество (с точки зрения метрики, которая оптимизируется)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и тестирование\n",
    "\n",
    "Обучение и тестирование модели проводится на непересекающихся множествах (train и test). Соотношения между размерами этих множеств - компромисс. В случае большой обучающий выборки получается более точный алгортим, но бОльший шум при оценки качества. При снижении объема обучающей выборки, алгоритм становится менее точным, зато получается менее шумная оценка качества.\n",
    "\n",
    "При решении задачи обучения по прецендентам приходится сравнивать различные модели и для каждой из моделей подбирать гиперпараметры. Для сравнения моделей необходимо измерять их качество. Качество можно либо измерять по описанной выше схеме, разделяя исходную выборку на обучающую и тренировочную, но в этом случае при большом переборе моделей и гиперпараметров произойдет переобучение на тестовую выборку (из-за того, что оценка качества, как правило, сильно зависит от разбиения выборки).\n",
    "\n",
    "Поэтому при сравнении моделей выборка разбивается разными способами на обучение и тест, а оценка качества вычисляется путем усреднения результатов на каждом из разбиений. Такой способ называется кросс-валидацией; есть различные схемы кросс-валидации:\n",
    "  - Leave-One-Out\n",
    "  - K-Fold\n",
    "  - Многократное случайное разбиение выборки\n",
    "\n",
    "Однако, такая процедура вычислительно затратна, особенно, если нужно перебрать большое число комбинаций гиперпараметров. Поэтому есть несколько способов упросить ее:\n",
    "\n",
    "- перебирать гиперпараметры с большим шагом; например, число деревьев для случайного леса перебирать в диапозоне `range(10, 100, 10)` вместо `range(10, 100, 1)`;\n",
    "- уменьшить количество фолдов в кросс-валидации (чревато зашумлением оценки качетсва);\n",
    "- оптимизировать гиперпараметры последовательно (есть риск пропустить хорошую комбинацию);\n",
    "- перебрать случайной подмножество из множество комбинаций гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных *data.adult.csv* с помощью `pandas`. Чтобы посмотреть данные, можно вызвать для загруженного `DataFrame` метод `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла)** Для некоторых объектов могут быть пропущены значения некоторых признаков. Пропуски могут обозначаться либо значением `numpy.nan`, либо каким-то определенным значением, которое указывается в описании к набору данных. В данном датасете пропущенные значения обозначены как \"?\". \n",
    "\n",
    "Некоторые алгоритмы могут работать некорректно с пропущенными значениями. Примените к выборке один из методов обработки пропущенных значений. Обоснуйте свой выбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее проделайте следующее:\n",
    " - Перемешайте объекты, чтобы исключить возможные последствия изначальной сортировки данных.\n",
    " - Выделите метки классов в отдельный вектор, удалите их из матрицы \"объект-признак\" и преобразуйте метки классов к бинарному формату (+1, -1).\n",
    " - Оставьте в датасете только вещественные признаки; сначала мы будем работать только с ними.\n",
    " \n",
    "Более подробно о работе с пропусками в Pandas можно прочитать например [здесь](http://pandas.pydata.org/pandas-docs/stable/missing_data.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение классификаторов на вещественных признаках\n",
    "\n",
    "**Важно!** Для оценки качества используйте метрику ROC-AUC.\n",
    "\n",
    "В начале посмотрим, как работает подбор параметров по сетке и как влияет на качество разбиение выборки. Сейчас и далее будем рассматривать 3 алгоритма:\n",
    " - [kNN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    " - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    " - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала оптимизируем один гиперпараметр у каждой из первых двух моделей:\n",
    " - kNN — число соседей (*n_neighbors*)\n",
    " - DecisonTree — глубина дерева (*max_depth*)\n",
    " \n",
    "Остальные параметры пусть принимают значения по умолчанию. Для подбора гиперпараметров воспользуйтесь перебором по сетке, который реализован в классе [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). В качестве схемы кросс-валидации используйте 5-Fold CV: [KFoldCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(6 баллов)** Для каждого алгоритма подберите оптимальные значения указанных гиперпараметров. Постройте график среднего значения качества по кросс-валидации алгоритма при заданном значении гиперпараметра, на котором также отобразите доверительный интервал (значение качества на каждом фолде, среднее значение качества и много другой полезной информации можно получить из поля [*cv results_*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)). Построение графика стоит выделить в отдельную функцию - это избавит вас от дублирования кода при выполнении дальнейшего задания.\n",
    "\n",
    "\n",
    "\n",
    "Что вы можете сказать о получившихся графиках?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла)** Также подберём число деревьев (*n_estimators*) в алгоритме RandomForest. В общем случае Random Forest не переобучается с увеличением количества деревьев. Подберите значение гиперпараметра, на которой ощутимый прирост качества перестает наблюдаться. Обратите внимание, что для проведения этого эксперимента не нужно с нуля обучать много случайных лесов с различными количествами деревьев. Обучите один случайный лес с максимальным интересным количеством деревьев, а затем рассмотрите подмножества деревьев разных размеров, состоящих из деревьев построенного леса (поле [*estimators_*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). В дальнейших экспериментах используйте подобранное количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 балла)** Качество алгоритмов может зависеть не только от значений гиперпараметров, но и от предобратки исходных признаков. Некоторые из рассматриваемых нами алгоритмов чувствительны к масштабу признаков. Посмотрим, насколько различны распределения признаков. Постройте гистограммы для признаков *age*, *fnlwgt*, *capital-gain*.\n",
    "\n",
    "Глядя на получившиеся графики, скажите в чем заключается особенность данных? На какие алгоритмы это может повлиять? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование признаков можно выполнить, например, одним из следующих способов:\n",
    " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке (см. функцию [scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html))\n",
    " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ — минимальный интервал значений признака\n",
    "\n",
    "Похожие схемы масштабирования приведены в классах [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) и [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler).\n",
    " \n",
    "**(2 балла)** Масштабируйте все вещественные признаки одним из указанных способов и подберите оптимальные значения гиперпараметров аналогично пункту выше.\n",
    "\n",
    "Изменилось ли качество у некоторых алгоритмов и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(8 баллов)** Теперь сделайте перебор гиперпараметров по сетке и найдите оптимальные комбинации для следующих моделей и гиперпараметров: \n",
    " - KNN — число соседей (*n_neighbors*) и метрика (*metric*)\n",
    " - DecisonTree — глубина дерева (*max_depth*) и критерий разбиения (*criterion*)\n",
    " - RandomForest — критерий разбиения в деревьях (*criterion*) и *max_features* (при фиксированном количестве деревьев, найденном ранее)\n",
    " \n",
    "Обратите внимание, что эта операция может быть ресурсо- и трудоемкой.\n",
    "\n",
    "Какой из алгоритмов имеет наилучшее качество?\n",
    "\n",
    "(для оптимизации кода и вычислений перед выполнением прочитайте следующее задание)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3 балла)** Сравните алгоритмы с точки зрения времени обучения. Обучение какого из алгоритмов работает дольше всего и почему?\n",
    "\n",
    "(hint: [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) подсчитывает не только качество на кросс-валидации, но и время работы алгоритмов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление категориальных признаков в модели\n",
    "\n",
    "Вспомним, что у нас еще есть категориальные признаки. Давайте посмотрим, как изменится качество модели после добавления этих признаков. \n",
    "\n",
    "**(1 балл)** Преобразуйте все категориальные признаки с помощью метода one-hot-encoding (например, это можно сделать с помощью функции [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) или [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) / [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) из sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как после кодирования признаков получилось достаточно много, в этой работе мы не будем добавлять их и подбирать заново оптимальные гиперпараметры (хотя правильнее было бы это сделать). \n",
    "\n",
    "**(3 балла)** Добавьте к масштабированным вещественным признакам закодированные категориальные и обучите алгоритмы с наилучшими гиперпараметрами из предыдущего пункта. Дало ли добавление новых признаков прирост качества? Измеряйте качество как и раньше используя 5-Fold CV. Для этого удобно воспользоваться функцией [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.cross_val_score.html#sklearn.cross_validation.cross_val_score).\n",
    "\n",
    "Отличается ли теперь наилучший классификатор от наилучшего в предыдущем пункте?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение построенных моделей\n",
    "\n",
    "**(4 балла)** После того как было построено много моделей хотелось бы сравнить их между собой. Воспользуйтесь \"ящиком с усами\" (boxplot) для сравнения алгоритмов между собой. \n",
    "\n",
    "Для каждого типа классификатора (kNN, DecisionTree, RandomForest) выберете тот, которых давал наилучшее качество на кросс-валидации и постройте диаграмму размаха (все классификаторы должны быть изображены на одном графике).\n",
    " \n",
    "Сделайте общие итоговые выводы о классификаторах с точки зрения их работы с признаками и сложности самой модели (какие гиперпараметры есть у модели, сильно ли изменение значения гиперпараметра влияет на качество модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
