{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "Результат работы − отчет в формате ноутбуков IPython (ipynb-файл). Код пишется на Python3. Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: мне − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.    \n",
    "Выполнение лабораторных работ занимает значительное время, поэтому не рекомендуем оставлять их на последний вечер перед сдачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) получают за всю лабораторную работу 0 баллов. Если вы нашли решение какого-то из заданий в открытом источнике, необходимо в комментариях к коду указать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "**Важно!!!** Прочитайте [руководство по написанию кода](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html). Работы, где будут грубо нарушены принципы оформления кода, будут штрафоваться!    \n",
    "Также помните, что самая главная ошибка, которую надо избегать, - дублирование кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Правила сдачи\n",
    "Выполненную работу следует отправить на почту `nikmort@ya.ru` с указанием темы `[FBB hw <номер домашнего задани> Surname Name]`, например `FBB hw 2 Ivanov Petr`. Название отправляемого файла должно иметь следующий формат: `N_Surname_Name.ipynb`, где `N` — номер домашнего задания. Например, `2_Ivanov_Petr.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "В этом задании вам будет предложено ознакомиться с двумя мощными библиотеками для машинного обучения - xgboost и keras. В первой реализован градиентный бустинг, во второй - нейронные сети. Ваша задача будет попробовать применить каждую из моделей к задаче мультиклассовой классификации и исследовать поведение моделей в зависимости от выбора параметров. Работать вам предстоит с  датасетом, составленным из рукописных \"картинок\" цифр. Он вам знаком по предыдущему заданию (можете брать код для работы с ним оттуда). Только в этот раз мы возьмем его полную версию - картинки будут размером 28х28 вместо 8х8, а общее число картинок - 42000 вместо 1797."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите датасет и разбейте его на выборки для обучения и контроля.\n",
    "\n",
    "Для ускорения работы возьмите небольшую часть датасета, например, 3%. Отладьте на ней код, а потом запустите расчеты на больших данных.\n",
    "\n",
    "Скорее всего, вычисления будут трудоемкими, если брать весь датасет, поэтому для итоговых вычислений можете взять только его часть (но не меньше 30%).\n",
    "\n",
    "Обратите внимание, что наблюдаемые результаты могут сильно зависеть от того, делаете ли вы эксперимент на маленьких или больших данных. Так, на выборке размера 100 ваш классификатор может легко переобучиться, в то время как на выборке размера 10000 этот эффект может не наблюдаться. Поэтому делайте выводы после запуска расчетов на больших данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FRACTION = .03\n",
    "\n",
    "def load_data():\n",
    "    data = pd.read_csv('train.csv')\n",
    "    data = data.sample(frac=SAMPLE_FRACTION)\n",
    "    labels = data['label'].values\n",
    "    digits = data.drop('label', 1).values\n",
    "    return digits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits, labels = load_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте в качестве базового решения посмотрим на известные нам алгоритмы. Возьмите kNN и Random Forest. Обучите их (гиперпараметры оставьте по умолчанию), подсчитайте точность и logloss на тестовой выборке. Какой алгоритм дал лучший результат? Как различаются алгоритмы по качеству и времени обучения и предсказания?\n",
    "\n",
    "hint: используйте %time для измерения времени работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее целевой метрикой для нас будет logloss. Точность также будем вычислять, как более интерпретируемую метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "(6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Установите библиотеку xgboost.](https://xgboost.readthedocs.io/en/latest/build.html) Реализация бустинга есть и в sklearn, но в ней уделено сильно меньше внимания регуляризации и скорости, поэтому мы будем использовать xgboost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмите классификатор с настройками по умолчанию (рекомендуется установить n_jobs на -1 для ускорения расчета). Документацию вы можете найти [тут](http://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost_classifier = XGBClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите его и предскажите метки для тестовой выборки. Выведите logloss, точность классификации и confusion matrix для обученного классификатора. Сравните время обучения и предсказания с предыдущими классификаторами. Склонен ли классификатор давать больше ошибок на определенных классах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Визуализируйте](https://stackoverflow.com/questions/33282368/plotting-a-2d-heatmap-with-matplotlib) важность признаков (feature importances) на картинке 28х28. Какие пиксели изображения наиболее важны для классификации? Как вы думаете, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем потюнить XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Выберите относительно большую learning_rate ($\\eta\\in[0.05,0.3]$), подберите оптимальное число деревьев для выбранного $\\eta$. В методе `fit` задайте `eval_metric`, равное `mlogloss`, в `eval_set` передайте `[(X_test, y_test)]`; таким образом, вы сможете получать качество вашей классификации после каждого обученного базового классификатора. Вы можете регулировать \"болтливость\" метода обучения с помощью параметры `verbose` (например, задать его равным 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте график зависимости качества классификации от числа базовых классификаторов (для этого можете воспользоваться методом `evals_result`). Для большей наглядности можете отдельно отобразить график по последним 60 точкам. Как вам кажется, какое количество базовых классификаторов будет оптимальным? \n",
    "\n",
    "Скорее всего, вы будете наблюдать выход качества на плато. Если вы хотите посмотреть на переобучение, попробуйте позапускать обучение на маленькой подвыборке (100-300 элементов), возможно, вы сможете его отловить. На больших сложных выборках переобучение обычно возникает при существенном количестве базовых классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируйте выбранное количество деревьев. Настройте параметры деревьев, начиная с самых значимых (`max_depth`, `min_child_weight`, `gamma`, `colsample_bytree`). Более подробно подробно про эти параметры вы можете почитать в документации, указанной выше. Не забывайте, что бустинг, как правило, хорошо работает на деревьях небольшой глубины.\n",
    "\n",
    "Правильно подбирать эти параметры по сетке, но данный перебор был бы чересчур трудоемким. Поэтому подбирайте их последовательно.\n",
    "\n",
    "Считать score на каждом шаге не нужно, сравнивайте только обученные классификаторы. Сохраняйте качество (accuracy и logloss) вашего классификатора после каждого настроенного параметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее таким же образом настройте регуляризацию ($\\lambda, \\alpha$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как все параметры настроены, уменьшите `learning_rate`, пропорционально увеличив число деревьев. Обучите итоговый классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте 2 графика:\n",
    "* по оси X отложены этапы настройки классификатора: по умолчанию, после выбора числа деревьев, после настройки каждого гиперпараметра, итоговый классификатор;\n",
    "* по оси Y на первом графике - accuracy на каждом этапе, на втором - logloss.\n",
    "\n",
    "Какой этап дал наиболее существенный прирост качества? Получилось ли у вас поднять качество выше, чем у базовых решений: kNN и Random Forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "(6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Установите библиотеку keras](https://keras.io/#installation). Возможно, вам также придется [установить библиотеку tensorflow](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки классов для keras необходимо задать не номером, а в виде индикаторов, показывающих принадлежность каждому из классов. Ниже приведен код, делающих это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве базового решения можете взять модель, которая демонстрировалась на лекции по нейронным сетям. \"Соберите\" сеть, обучите ее и сделайте предсказание. В качестве `batch_size` возьмите 1-2% объема обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем подобрать структуру сети. Каких-то четких инструкций здесь нет, это довольно творческий процесс. Попробуйте варьировать следующие параметры:\n",
    "* число Dense слоев (рекомендуется брать не более пяти); не забывайте после каждого Dense слоя добавлять слой активации; помните, что при большом числе слоев обучение может идти медленно и может потребоваться существенное число эпох для того, что наблюдать прирост качества.\n",
    "* количество нейронов на слоях; как правило, сети проектируют так, чтобы слои сужались: сначала шли слои с большим количеством нейронов, потом - с меньшим.\n",
    "* слои Dropout - вы можете добавить эти слои после скрытых слоев активации.\n",
    "\n",
    "Также, как и в случае с xgboost, сохраняйте наилучший результат по качеству на каждом шаге.\n",
    "\n",
    "Составьте 6-7 разных моделей и посмотрите, какое на них будет качество классификации. Сильно ли зависит результат и время обучения от конфигурации модели?\n",
    "\n",
    "Ниже дано описание класса, с помощью которого можно логировать время обучения. Просто передайте в `fit` параметр `callbacks=[time_callback]`. После обучения вы можете получить время на каждой эпохе с помощью `time_callback.times`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43178668/record-the-computation-time-for-each-epoch-in-keras-during-model-fit\n",
    "import time \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "        \n",
    "time_callback = TimeHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите 1-2 модели, которые дали наилучший результат. Подберите параметры в них: попробуйте выбрать различные функции активации, коэффициент Dropout, коэффициенты регуляризации. Проведите порядка 10 экспериментов. Как настройка слоев влияет на качество модели? Сильно ли различается результат?\n",
    "\n",
    "Коэффициенты регуляризации передаются в Dense слои с помощью `kernel_regularizer=l2(l2_coef)`. Рекомендуется провести эксперимент с коэффициентами от $10^{-6}$ до $10^{-4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попытайтесь подобрать для SGD начальный `learning_rate`, темп его снижения `decay`. Диапазоны параметров, с которыми рекомендуется провести эксперименты:\n",
    "- `learning rate`: от 0.005 до 0.1,\n",
    "- `decay`: от $10^{-9}$ до $10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите лучшую сеть, обучите ее и оцените качество. Сделайте графики зависимости качества классификации от этапа настройки параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, правильно было бы попробовать и ее, но тогда задание получится чрезмерно трудоемким. =) Поэтому этот пункт необязателен к выполнению. Однако, вы можете самостоятельно разобраться в конструировании сверточных сетей и оценить качество их работы. Для построения сверточного блока вам необходимо реализовать последовательность свертки ([Convolution2D](https://keras.io/layers/convolutional/#conv2d)), нелинейности (ReLU) и пулинга ([MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d)). Почитайте документацию, посмотрите примеры сверточных сетей в аналогичных работах.\n",
    "\n",
    "Да, бонусные баллы (до +6) за реализацию этого пункта ставиться будут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "(3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните наилучшую модель, полученную на xgboost, с наилучшей моделью, обученной с помощью keras.\n",
    "\n",
    "Как различаются точность, logloss, время обучения? Какую модель легче и удобнее настраивать? Какая модель вам показалась наиболее гибкой?\n",
    "\n",
    "Какие плюсы и минусы вы бы отметили у двух данных моделей машинного обучения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Обучите модели, взяв всю выборку (42000 объектов). Конечно, из-за перехода к более объемной выборке правильно будет подбирать параметры заново, но можете оставить текущие параметры, увеличив число деревьев в XGBoost или число эпох в нейронной сети, слегка снизив `learning_rate`). [Скачайте с kaggle](https://www.kaggle.com/c/digit-recognizer/data) набор тестовых данных, сделайте на них предсказание для каждой модели и отправьте оба результата (submit predictions) в Kaggle.\n",
    "\n",
    "Какой результат у вас получился? Сильно ли он отличается от того, что вы видели на эксперименте?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
